<span style='font-size: 12px; font-weight: normal; opacity: 0.6;'>Task Type</span>,<span style='visibility: hidden;'>dummy</span>,,,,,,,<a id=8 href='https://euroeval.com/tasks/sentiment-classification/' style='font-size: 12px; font-weight: normal; color: Grey; text-decoration: underline;'>Sentiment classification</a>,<a id=9 href='https://euroeval.com/tasks/named-entity-recognition/' style='font-size: 12px; font-weight: normal; color: Grey; text-decoration: underline;'>Named entity recognition</a>,<a id=10 href='https://euroeval.com/tasks/linguistic-acceptability/' style='font-size: 12px; font-weight: normal; color: Grey; text-decoration: underline;'>Linguistic acceptability</a>,<a id=11 href='https://euroeval.com/tasks/reading-comprehension/' style='font-size: 12px; font-weight: normal; color: Grey; text-decoration: underline;'>Reading comprehension</a>,<span style='visibility: hidden;'>hidden</span>,,,
model,generative_type,rank,parameters,vocabulary_size,context,commercial,merge,<a href='https://euroeval.com/datasets/polish#polemo2'>polemo2</a>,<a href='https://euroeval.com/datasets/polish#kpwr-ner'>kpwr_ner</a>,<a href='https://euroeval.com/datasets/polish#scala-pl'>scala_pl</a>,<a href='https://euroeval.com/datasets/polish#poquad'>poquad</a>,polemo2_version,kpwr_ner_version,scala_pl_version,poquad_version
<a href='https://hf.co/Qwen/Qwen2.5-72B-Instruct'>Qwen/Qwen2.5-72B-Instruct</a>,📝,1.20@@1.20,72706203648,152064,32768,✓,✗,89.27 ± 0.89 / 90.67 ± 0.91@@89.27,57.32 ± 1.42 / 42.97 ± 1.88@@57.32,50.35 ± 1.61 / 75.14 ± 0.79@@50.35,51.61 ± 1.01 / 23.36 ± 0.95@@51.61,16.2.2.dev0@@160202,16.2.2.dev0@@160202,16.2.2.dev0@@160202,16.2.2.dev0@@160202
<a href='https://hf.co/jhu-clsp/mmBERT-base'>jhu-clsp/mmBERT-base</a>,🔍,1.30@@1.30,307531778,256000,8192,✓,✗,93.30 ± 0.95 / 95.69 ± 0.63@@93.30,62.50 ± 2.85 / 61.68 ± 1.62@@62.50,46.94 ± 3.22 / 72.99 ± 1.65@@46.94,40.57 ± 1.53 / 18.71 ± 0.80@@40.57,16.1.1.dev0@@160101,16.1.1.dev0@@160101,16.1.1.dev0@@160101,16.1.1.dev0@@160101
<a href='https://hf.co/google/gemma-3n-E4B-it'>google/gemma-3n-E4B-it</a>,📝,1.51@@1.51,7849978192,262400,8192,✓,✗,90.08 ± 0.61 / 91.60 ± 0.56@@90.08,52.75 ± 0.74 / 35.69 ± 1.54@@52.75,32.13 ± 2.06 / 64.57 ± 1.48@@32.13,46.33 ± 0.98 / 21.92 ± 0.56@@46.33,16.2.2.dev0@@160202,16.2.2.dev0@@160202,16.2.2.dev0@@160202,16.2.2.dev0@@160202
<a href='https://hf.co/jhu-clsp/mmBERT-small'>jhu-clsp/mmBERT-small</a>,🔍,1.74@@1.74,140642306,256000,8192,✓,✗,88.85 ± 2.67 / 92.95 ± 1.72@@88.85,60.30 ± 3.05 / 60.10 ± 2.48@@60.30,36.50 ± 6.57 / 68.04 ± 3.27@@36.50,19.61 ± 4.39 / 7.01 ± 2.06@@19.61,16.1.1.dev0@@160101,16.1.1.dev0@@160101,16.1.1.dev0@@160101,16.1.1.dev0@@160101
<a href='https://hf.co/Qwen/Qwen3-1.7B'>Qwen/Qwen3-1.7B</a>,🤔,1.93@@1.93,2031739904,151936,40960,✓,✗,78.59 ± 1.19 / 78.09 ± 1.65@@78.59,45.03 ± 1.70 / 32.25 ± 1.77@@45.03,20.62 ± 1.43 / 60.28 ± 0.70@@20.62,42.15 ± 0.65 / 22.70 ± 0.45@@42.15,16.2.2.dev0@@160202,16.2.2.dev0@@160202,16.2.2.dev0@@160202,16.2.2.dev0@@160202
<a href='https://hf.co/TildeAI/TildeOpen-30b'>TildeAI/TildeOpen-30b#slow-tokenizer</a>,🧠,1.96@@1.96,30677882880,131072,65536,✓,✗,48.08 ± 1.61 / 47.68 ± 2.71@@48.08,46.87 ± 1.72 / 38.28 ± 1.77@@46.87,16.78 ± 3.47 / 54.22 ± 3.89@@16.78,59.64 ± 3.09 / 34.66 ± 2.53@@59.64,16.2.2.dev0@@160202,16.2.2.dev0@@160202,16.2.2.dev0@@160202,16.2.2.dev0@@160202
<a href='https://hf.co/Qwen/Qwen3-0.6B'>Qwen/Qwen3-0.6B#no-thinking</a>,📝,2.63@@2.63,751632384,151936,40960,✓,✗,61.85 ± 1.20 / 55.41 ± 1.19@@61.85,26.99 ± 1.84 / 18.82 ± 1.86@@26.99,3.71 ± 1.34 / 42.10 ± 3.82@@3.71,33.68 ± 0.80 / 14.86 ± 0.73@@33.68,16.1.1.dev0@@160101,16.1.1.dev0@@160101,16.1.1.dev0@@160101,16.1.1.dev0@@160101
<a href='https://hf.co/Qwen/Qwen3-0.6B'>Qwen/Qwen3-0.6B</a>,🤔,2.65@@2.65,751632384,151936,40960,✓,✗,59.12 ± 2.27 / 59.38 ± 1.19@@59.12,26.93 ± 1.82 / 20.68 ± 1.71@@26.93,4.02 ± 1.61 / 46.59 ± 1.19@@4.02,32.96 ± 0.80 / 17.42 ± 0.57@@32.96,16.2.2.dev0@@160202,16.2.2.dev0@@160202,16.2.2.dev0@@160202,16.2.2.dev0@@160202
<a href='https://hf.co/HuggingFaceTB/SmolLM2-360M-Instruct'>HuggingFaceTB/SmolLM2-360M-Instruct</a>,📝,3.53@@3.53,361821120,49152,8192,✓,✗,9.70 ± 4.01 / 29.48 ± 3.76@@9.70,11.62 ± 2.10 / 11.35 ± 2.01@@11.62,-0.14 ± 2.27 / 40.13 ± 4.49@@-0.14,9.29 ± 1.03 / 1.98 ± 0.64@@9.29,16.2.2.dev0@@160202,16.2.2.dev0@@160202,16.2.2.dev0@@160202,16.2.2.dev0@@160202
<a href='https://hf.co/HuggingFaceTB/SmolLM2-360M'>HuggingFaceTB/SmolLM2-360M</a>,🧠,3.55@@3.55,361821120,49152,8192,✓,✗,0.83 ± 2.67 / 17.57 ± 0.78@@0.83,16.11 ± 1.30 / 16.68 ± 1.16@@16.11,-3.22 ± 2.10 / 37.89 ± 3.68@@-3.22,10.70 ± 1.64 / 4.11 ± 1.30@@10.70,16.2.2.dev0@@160202,16.2.2.dev0@@160202,16.2.2.dev0@@160202,16.2.2.dev0@@160202
<a href='https://hf.co/HuggingFaceTB/SmolLM2-135M-Instruct'>HuggingFaceTB/SmolLM2-135M-Instruct</a>,📝,3.69@@3.69,134515008,49152,8192,✓,✗,4.79 ± 3.79 / 27.80 ± 3.73@@4.79,9.21 ± 2.61 / 10.29 ± 1.40@@9.21,1.14 ± 2.02 / 37.81 ± 3.74@@1.14,4.24 ± 0.38 / 0.15 ± 0.13@@4.24,16.2.2.dev0@@160202,16.2.2.dev0@@160202,16.2.2.dev0@@160202,16.2.2.dev0@@160202
<a href='https://hf.co/HuggingFaceTB/SmolLM2-135M'>HuggingFaceTB/SmolLM2-135M</a>,🧠,3.70@@3.70,134515008,49152,8192,✓,✗,3.70 ± 3.84 / 17.56 ± 2.92@@3.70,12.03 ± 1.48 / 11.86 ± 1.42@@12.03,-1.62 ± 1.35 / 37.54 ± 3.67@@-1.62,3.55 ± 0.29 / 0.50 ± 0.33@@3.55,16.2.2.dev0@@160202,16.2.2.dev0@@160202,16.2.2.dev0@@160202,16.2.2.dev0@@160202
<a href='https://hf.co/Qwen/Qwen3-4B'>Qwen/Qwen3-4B</a>,🤔,-@@100,4022468096,151936,40960,✓,✗,84.22 ± 1.18 / 84.52 ± 1.49@@84.22,-@@-1,-@@-1,-@@-1,16.2.2.dev0@@160202,-@@0,-@@0,-@@0
