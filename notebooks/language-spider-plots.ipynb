{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/EuroEval/leaderboards/refs/heads/main/leaderboards/european_all.csv\"\n",
    ")\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = [col for col in df.columns if col.endswith(\"_version\")]\n",
    "columns_to_drop += [col.replace(\"_version\", \"\") for col in columns_to_drop]\n",
    "columns_to_drop += [\n",
    "    \"generative_type\",\n",
    "    \"parameters\",\n",
    "    \"vocabulary_size\",\n",
    "    \"context\",\n",
    "    \"commercial\",\n",
    "    \"merge\",\n",
    "    \"rank\",\n",
    "]\n",
    "\n",
    "clean_df = (\n",
    "    df.map(lambda x: x.split(\"@@\")[0] if isinstance(x, str) else x)\n",
    "    .map(lambda x: re.sub(r\"<.*?>(.*?)</.*>\", r\"\\1\", x) if isinstance(x, str) else x)\n",
    "    .map(lambda x: re.sub(r\"^(gemini|xai)/\", \"\", x) if isinstance(x, str) else x)\n",
    "    .map(lambda x: None if x == \"-\" else x)\n",
    "    .drop(columns=columns_to_drop)\n",
    "    .dropna()\n",
    "    .set_index(\"model\")\n",
    "    .map(float)\n",
    ")\n",
    "\n",
    "zero_shot_df = (\n",
    "    clean_df.reset_index()\n",
    "    .map(lambda x: None if isinstance(x, str) and \"few-shot\" in x else x)\n",
    "    .map(lambda x: re.sub(r\" *\\(.*\\)\", \"\", x) if isinstance(x, str) else x)\n",
    "    .dropna()\n",
    "    .set_index(\"model\")\n",
    ")\n",
    "\n",
    "few_shot_df = (\n",
    "    clean_df.reset_index()\n",
    "    .map(lambda x: None if isinstance(x, str) and \"few-shot\" not in x else x)\n",
    "    .map(lambda x: re.sub(r\" *\\(.*\\)\", \"\", x) if isinstance(x, str) else x)\n",
    "    .map(lambda x: re.sub(r\"^.*/\", \"\", x) if isinstance(x, str) else x)\n",
    "    .dropna()\n",
    "    .set_index(\"model\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_models(\n",
    "    df: pd.DataFrame, models: list[str], title: str, max_score: float\n",
    ") -> None:\n",
    "    \"\"\"Create a spider plot of a list of models.\"\"\"\n",
    "    fig = go.Figure()\n",
    "\n",
    "    for model in models:\n",
    "        model_scores = df.loc[model, :].tolist()\n",
    "        trace = go.Scatterpolar(\n",
    "            r=model_scores,\n",
    "            theta=[x.capitalize() for x in clean_df.columns],\n",
    "            name=model,\n",
    "            fill=\"toself\",\n",
    "        )\n",
    "        fig.add_trace(trace)\n",
    "\n",
    "    fig.update_layout(\n",
    "        polar=dict(radialaxis=dict(range=[max_score, 1])),\n",
    "        showlegend=True,\n",
    "        title=title.strip() + \" (smaller is better)\",\n",
    "        width=800,\n",
    "        height=500,\n",
    "    )\n",
    "    fig.show(config=dict(toImageButtonOptions=dict(scale=6)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_models(\n",
    "    df=zero_shot_df,\n",
    "    models=[\n",
    "        \"o3-2025-04-16\",\n",
    "        \"gemini-2.5-pro-preview-03-25\",\n",
    "        \"gemini-2.5-flash-preview-04-17\",\n",
    "    ],\n",
    "    title=\"Zero-shot Performance of SOTA Reasoning LLMs\",\n",
    "    max_score=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_models(\n",
    "    df=zero_shot_df,\n",
    "    models=[\n",
    "        \"gpt-4.1-2025-04-14\",\n",
    "        \"grok-3-beta\",\n",
    "        \"claude-3-5-sonnet-20241022\",\n",
    "        \"gemini-2.0-flash-001\",\n",
    "    ],\n",
    "    title=\"Zero-shot Performance of SOTA Non-Reasoning LLMs\",\n",
    "    max_score=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_models(\n",
    "    df=few_shot_df,\n",
    "    models=[\n",
    "        \"SmolLM2-360M\",\n",
    "        \"Pleias-Pico\",\n",
    "        \"gpt-sw3-356m\",\n",
    "    ],\n",
    "    title=\"Few-shot Performance of ~300M LMs\",\n",
    "    max_score=7,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_models(\n",
    "    df=few_shot_df,\n",
    "    models=[\n",
    "        \"Llama-3.2-1B-Instruct\",\n",
    "        \"gemma-3-1b-it\",\n",
    "        \"Pleias-1.2b-Preview\",\n",
    "    ],\n",
    "    title=\"Few-shot Performance of ~1B LMs\",\n",
    "    max_score=6,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_models(\n",
    "    df=few_shot_df,\n",
    "    models=[\n",
    "        \"gemma-3-12b-it\",\n",
    "        \"cogito-v1-preview-llama-8B\",\n",
    "        \"Llama-3.1-8B-Instruct\",\n",
    "        \"EuroLLM-9B-Instruct\",\n",
    "        \"occiglot-7b-eu5-instruct\",\n",
    "        \"Teuken-7B-instruct-commercial-v0.4\",\n",
    "    ],\n",
    "    title=\"Few-shot Performance of ~8B LMs\",\n",
    "    max_score=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_models(\n",
    "    df=few_shot_df,\n",
    "    models=[\n",
    "        \"gemma-3-27b-it\",\n",
    "        \"Mistral-Small-24B-Instruct-2501\",\n",
    "        \"aya-expanse-32b\",\n",
    "    ],\n",
    "    title=\"Few-shot Performance of ~30B LMs\",\n",
    "    max_score=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_models(\n",
    "    df=few_shot_df,\n",
    "    models=[\n",
    "        \"Meta-Llama-3-70B\",\n",
    "        \"Llama-3.3-70B-Instruct\",\n",
    "        \"Qwen2.5-72B-Instruct\",\n",
    "    ],\n",
    "    title=\"Few-shot Performance of ~70B LMs\",\n",
    "    max_score=3,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
